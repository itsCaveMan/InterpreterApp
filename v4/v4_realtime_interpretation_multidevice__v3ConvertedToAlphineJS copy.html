<!--

    DOCUMENTATION:
    - The purpose of this page is to interpret the users speech from one language to another language.
    - This page makes use of the device's microphone and speaker.
    - The page creates a session with OpenAI Realtime to handle the interpretation. 
    
    - OPENAI REALTIME DOCUMENTATION:
        - The Realtime turn detection is manual, and handled by this page.
        - This page controls who's turn it is to speak (between the user input or Realtime response).
        - This page captures all the micrphone input, and keeps it in a buffer.
        - The page creates a que of blocks(sentences/phrases) from the user's speech to be sent to OpenAI Realtime.
        - When the response from 1 block is finished, the page sends the next block to OpenAI Realtime.

    THE BARGIN PROBLEM: 
    - the Realtime service will cut off if the user starts talking. This is called bargin. it is a result of auto matic turn detection. 
    - An example is: A user speaks a sentence and it's sent to Realtime. Realtime starts streaming the response, however as the user starts speaking agian, the Realtime stream is cut. The user "barged in" 
    - this results in a very unsmooth interpretation experience. 
    - The goal is that the user can continuously speak comfortably, and this page will dynamically handle the audio chunks + Realtime so that all the audio is A) sent to Realtime, and B) the response is played out completely. 


-->

<!-- Working realtime. however bargin is not solved here -->
<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Real-time Translation Service</title>
    <script src="https://cdn.tailwindcss.com"></script>

    <script>
        window.translatorComponent = function () {
            return {
                session: null,
                localStream: null,
                isConnected: false,
                

                apiKey: '',
                prompt: 'Translate this English to Korean',
                statusMessage: 'Ready to start',
                isBusy: false,

                init() {
                    const savedApiKey = localStorage.getItem('openai-api-key');
                    const savedPrompt = localStorage.getItem('translation-prompt');
                    if (savedApiKey) this.apiKey = savedApiKey;
                    if (savedPrompt) this.prompt = savedPrompt;
                    this.$watch('apiKey', (v) => localStorage.setItem('openai-api-key', v));
                    this.$watch('prompt', (v) => localStorage.setItem('translation-prompt', v));
                },

                updateStatus(message) {
                    this.statusMessage = message;
                },

                async toggleSession() {
                    if (!this.isConnected) {
                        await this.startSession();
                    } else {
                        this.stopSession();
                    }
                },

                async startSession() {
                    const apiKey = (this.apiKey || '').trim();
                    const prompt = (this.prompt || '').trim();
                    if (!apiKey) {
                        this.updateStatus('Please enter your OpenAI API key');
                        return;
                    }
                    if (!prompt) {
                        this.updateStatus('Please enter a translation prompt');
                        return;
                    }

                    try {
                        this.isBusy = true;
                        this.updateStatus('Requesting microphone...');

                        this.localStream = await navigator.mediaDevices.getUserMedia({
                            audio: {
                                echoCancellation: true,
                                noiseSuppression: true,
                                autoGainControl: true
                            }
                        });

                        const micTrack = this.localStream.getAudioTracks()[0];
                        await this.createSession(micTrack, apiKey, prompt);
                        this.isBusy = false;
                    } catch (error) {
                        console.error('Error starting sessions:', error);
                        this.updateStatus('Error: ' + (error && error.message ? error.message : String(error)));
                        this.isBusy = false;
                        this.stopSession();
                    }
                },

                async getClientToken(keyOrToken) {
                    const looksLikeRealKey = keyOrToken.startsWith('sk-');
                    if (!looksLikeRealKey) return keyOrToken;
                    this.updateStatus('Creating ephemeral token...');
                    const response = await fetch('https://api.openai.com/v1/realtime/sessions', {
                        method: 'POST',
                        headers: {
                            'Authorization': `Bearer ${keyOrToken}`,
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            model: 'gpt-4o-realtime-preview',
                            voice: 'alloy'
                        }),
                    });
                    if (!response.ok) {
                        throw new Error(`Failed to create session (${response.status})`);
                    }
                    const data = await response.json();
                    const token = data && data.client_secret && data.client_secret.value;
                    if (!token) {
                        throw new Error('No client_secret.value in session response');
                    }
                    return token;
                },

                async waitForIceGathering(conn) {
                    if (conn.iceGatheringState === 'complete') return;
                    await new Promise((resolve) => {
                        const check = () => {
                            if (conn.iceGatheringState === 'complete') {
                                conn.removeEventListener('icegatheringstatechange', check);
                                resolve();
                            }
                        };
                        conn.addEventListener('icegatheringstatechange', check);
                    });
                },

                async createSession(micTrack, keyOrToken, prompt) {
                    try {
                        const clientToken = await this.getClientToken(keyOrToken);
                        const pc = new RTCPeerConnection({
                            iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
                        });

                        const localStreamForThisSession = new MediaStream([micTrack]);
                        pc.addTrack(micTrack, localStreamForThisSession);

                        const inboundStream = new MediaStream();
                        pc.ontrack = (event) => {
                            inboundStream.addTrack(event.track);
                            const audioEl = this.$refs.audio;
                            audioEl.srcObject = inboundStream;
                            audioEl.play();
                        };

                        pc.onconnectionstatechange = () => {
                            console.log(`Session state:`, pc.connectionState);
                            if (['failed', 'disconnected', 'closed'].includes(pc.connectionState)) {
                                this.stopSession();
                            }
                        };

                        const dc = pc.createDataChannel(`oai-events`);
                        dc.onopen = () => {
                            dc.send(JSON.stringify({
                                type: 'session.update',
                                session: {
                                    instructions: prompt,
                                    turn_detection: {
                                        type: 'server_vad',
                                        create_response: true
                                    },
                                    voice: 'alloy',
                                    modalities: ['audio', 'text']
                                }
                            }));
                            this.isConnected = true;
                            this.updateStatus('Connected - Speak now');
                        };

                        dc.onmessage = (event) => {
                            // Message handling not required for single-session switching
                        };

                        const offer = await pc.createOffer({ offerToReceiveAudio: true });
                        await pc.setLocalDescription(offer);
                        await this.waitForIceGathering(pc);

                        const sdpResponse = await fetch('https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview', {
                            method: 'POST',
                            headers: {
                                'Authorization': `Bearer ${clientToken}`,
                                'Content-Type': 'application/sdp',
                            },
                            body: pc.localDescription.sdp,
                        });
                        if (!sdpResponse.ok) {
                            throw new Error(`SDP exchange failed: ${sdpResponse.status} ${sdpResponse.statusText}`);
                        }
                        const answerSdp = await sdpResponse.text();
                        await pc.setRemoteDescription({ type: 'answer', sdp: answerSdp });

                        micTrack.enabled = true;
                        const audioEl = this.$refs.audio;
                        this.session = { pc, dc, inboundStream, audioElement: audioEl, micTrack };
                    } catch (error) {
                        console.error('Session connection error:', error);
                        this.updateStatus('Error: ' + (error && error.message ? error.message : String(error)));
                        throw error;
                    }
                },

                stopSession() {
                    this.updateStatus('Disconnecting...');
                    const s = this.session;
                    if (s) {
                        try {
                            if (s.dc && s.dc.readyState === 'open') s.dc.close();
                        } catch (_) {}
                        try {
                            if (s.pc) s.pc.close();
                        } catch (_) {}
                        try {
                            if (s.micTrack) s.micTrack.stop();
                        } catch (_) {}
                    }
                    this.session = null;
                    if (this.localStream) {
                        this.localStream.getTracks().forEach((track) => track.stop());
                    }
                    this.localStream = null;
                    this.isConnected = false;
                    this.resetUI();
                },

                resetUI() {
                    this.isBusy = false;
                    this.updateStatus('Ready to start');
                },
            };
        };
    </script>

    <script defer src="https://cdn.jsdelivr.net/npm/alpinejs@3.x.x/dist/cdn.min.js"></script>
</head>
<body class="bg-gray-50 min-h-screen">
    <div class="container mx-auto px-4 py-6 max-w-md" x-data="translatorComponent()">
        <h1 class="text-2xl font-bold text-center mb-6 text-gray-800">
            Real-time Translation
        </h1>
        
        <div class="mb-4">
            <label for="apiKey" class="block text-sm font-medium text-gray-700 mb-2">
                OpenAI API Key
            </label>
            <input 
                type="password" 
                id="apiKey" 
                placeholder="Enter your OpenAI API key"
                class="w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm focus:outline-none focus:ring-blue-500 focus:border-blue-500"
                x-model="apiKey"
            >
        </div>

        <div class="mb-4">
            <label for="prompt" class="block text-sm font-medium text-gray-700 mb-2">
                Translation Prompt
            </label>
            <textarea 
                id="prompt" 
                rows="3"
                placeholder="e.g., Translate this English to Korean"
                class="w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm focus:outline-none focus:ring-blue-500 focus:border-blue-500 resize-none"
                x-model="prompt"
            ></textarea>
        </div>

        <div class="mb-6">
            <button 
                class="w-full bg-blue-600 hover:bg-blue-700 disabled:bg-gray-400 text-white font-medium py-3 px-4 rounded-md transition-colors"
                @click="toggleSession()"
                :disabled="isBusy"
                x-text="isConnected ? 'Stop Translation Session' : 'Start Translation Session'"
            ></button>
        </div>

        <div class="text-center text-sm text-gray-600 mb-4" x-text="statusMessage"></div>

        <audio x-ref="audio" autoplay playsinline class="hidden"></audio>
    </div>
</body>
</html>

