<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Korean Correction</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background-color: #f8f9fa;
            padding: 20px;
            color: #333;
        }
        
        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            padding: 30px;
        }
        
        h1 {
            text-align: center;
            margin-bottom: 30px;
            color: #2c3e50;
            font-weight: 300;
        }
        
        .form-group {
            margin-bottom: 20px;
        }
        
        label {
            display: block;
            margin-bottom: 5px;
            font-weight: 500;
            color: #555;
        }
        
        input[type="text"], input[type="password"], textarea {
            width: 100%;
            padding: 12px;
            border: 1px solid #ddd;
            border-radius: 4px;
            font-size: 14px;
            transition: border-color 0.3s;
        }
        
        input[type="text"]:focus, input[type="password"]:focus, textarea:focus {
            outline: none;
            border-color: #007bff;
        }
        
        textarea {
            resize: vertical;
            min-height: 120px;
        }
        
        .api-key-group {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 4px;
            margin-bottom: 20px;
        }
        
        .controls {
            display: flex;
            gap: 15px;
            align-items: center;
            justify-content: center;
            margin: 30px 0;
        }
        
        .mic-button {
            background: #dc3545;
            color: white;
            border: none;
            padding: 15px 20px;
            border-radius: 50px;
            font-size: 16px;
            cursor: pointer;
            transition: all 0.3s;
            display: flex;
            align-items: center;
            gap: 8px;
            min-width: 150px;
            justify-content: center;
        }
        
        .mic-button:hover {
            background: #c82333;
            transform: scale(1.05);
        }
        
        .mic-button.recording {
            background: #28a745;
            animation: pulse 2s infinite;
        }
        
        .mic-button.recording:hover {
            background: #218838;
        }
        
        .mic-button:disabled {
            background: #6c757d;
            cursor: not-allowed;
            transform: none;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        
        .status {
            text-align: center;
            padding: 15px;
            border-radius: 4px;
            margin: 20px 0;
            font-weight: 500;
        }
        
        .status.connected {
            background: #d4edda;
            color: #155724;
        }
        
        .status.disconnected {
            background: #f8d7da;
            color: #721c24;
        }
        
        .status.connecting {
            background: #fff3cd;
            color: #856404;
        }
        
        .conversation {
            background: #f8f9fa;
            border-radius: 8px;
            padding: 20px;
            margin-top: 20px;
            max-height: 400px;
            overflow-y: auto;
        }
        
        .message {
            margin-bottom: 15px;
            padding: 10px;
            border-radius: 6px;
            line-height: 1.5;
        }
        
        .message.user {
            background: #e3f2fd;
            border-left: 4px solid #2196f3;
        }
        
        .message.assistant {
            background: #e8f5e8;
            border-left: 4px solid #4caf50;
        }
        
        .message.error {
            background: #ffebee;
            border-left: 4px solid #f44336;
        }
        
        .message-label {
            font-weight: bold;
            margin-bottom: 5px;
            font-size: 12px;
            text-transform: uppercase;
            opacity: 0.8;
        }
        
        .audio-controls {
            display: flex;
            gap: 10px;
            margin-top: 10px;
        }
        
        .audio-button {
            background: #007bff;
            color: white;
            border: none;
            padding: 10px 15px;
            border-radius: 6px;
            font-size: 14px;
            cursor: pointer;
            transition: all 0.3s;
            display: flex;
            align-items: center;
            gap: 5px;
        }
        
        .audio-button:hover {
            background: #0056b3;
            transform: scale(1.05);
        }
        
        .audio-button:disabled {
            background: #6c757d;
            cursor: not-allowed;
            transform: none;
        }
        
        .controls label {
            display: flex;
            align-items: center;
            gap: 8px;
            font-size: 14px;
            color: #555;
        }
        
        .error {
            background: #f8d7da;
            color: #721c24;
            padding: 12px;
            border-radius: 4px;
            margin: 20px 0;
        }
        
        .mic-icon {
            font-size: 18px;
        }
        
        .volume-indicator {
            width: 30px;
            height: 30px;
            border-radius: 50%;
            background: #ddd;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: background-color 0.1s;
        }
        
        .volume-indicator.active {
            background: #28a745;
        }
        
        /* Debug Panel Styles */
        .debug-panel {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            margin-top: 20px;
            overflow: hidden;
        }
        
        .debug-header {
            background: #e9ecef;
            padding: 12px 16px;
            border-bottom: 1px solid #dee2e6;
            cursor: pointer;
            display: flex;
            justify-content: space-between;
            align-items: center;
            font-weight: 600;
        }
        
        .debug-header:hover {
            background: #dee2e6;
        }
        
        .debug-content {
            padding: 16px;
            max-height: 400px;
            overflow-y: auto;
        }
        
        .debug-content.collapsed {
            display: none;
        }
        
        .debug-log {
            background: #2d3748;
            color: #e2e8f0;
            padding: 12px;
            border-radius: 4px;
            font-family: 'Monaco', 'Menlo', monospace;
            font-size: 12px;
            line-height: 1.4;
            max-height: 300px;
            overflow-y: auto;
            margin-bottom: 16px;
        }
        
        .debug-log .timestamp {
            color: #90cdf4;
            font-weight: bold;
        }
        
        .debug-log .request {
            color: #68d391;
        }
        
        .debug-log .response {
            color: #fbb6ce;
        }
        
        .debug-log .error {
            color: #fc8181;
        }
        
        .debug-log .info {
            color: #90cdf4;
        }
        
        .audio-visualizer {
            background: #2d3748;
            border-radius: 4px;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        .waveform-container {
            display: flex;
            align-items: center;
            gap: 8px;
            margin-bottom: 12px;
        }
        
        .waveform-bars {
            display: flex;
            align-items: end;
            gap: 2px;
            height: 60px;
            flex: 1;
        }
        
        .waveform-bar {
            width: 3px;
            background: #4a5568;
            border-radius: 2px;
            transition: height 0.1s ease;
        }
        
        .waveform-bar.active {
            background: #68d391;
        }
        
        .audio-stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 12px;
            font-size: 12px;
            color: #a0aec0;
        }
        
        .audio-stat {
            background: #4a5568;
            padding: 8px 12px;
            border-radius: 4px;
        }
        
        .audio-stat-label {
            color: #e2e8f0;
            font-weight: 600;
        }
        
        .audio-stat-value {
            color: #90cdf4;
        }
        
        .debug-actions {
            display: flex;
            gap: 10px;
            margin-top: 12px;
        }
        
        .debug-btn {
            background: #4a5568;
            color: white;
            border: none;
            padding: 6px 12px;
            border-radius: 4px;
            font-size: 12px;
            cursor: pointer;
            transition: background-color 0.2s;
        }
        
        .debug-btn:hover {
            background: #2d3748;
        }
        
        .connection-status {
            display: flex;
            align-items: center;
            gap: 8px;
            font-size: 12px;
            margin-bottom: 12px;
        }
        
        .connection-dot {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            background: #fc8181;
        }
        
        .connection-dot.connected {
            background: #68d391;
        }
        
        .connection-dot.connecting {
            background: #f6e05e;
            animation: pulse 1s infinite;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Real-time Korean Correction</h1>
        
        <div class="api-key-group">
            <div class="form-group">
                <label for="apiKey">OpenAI API Key:</label>
                <input type="password" id="apiKey" placeholder="sk-..." required>
            </div>
        </div>
        
        <div class="form-group">
            <label for="systemInstructions">System Instructions:</label>
            <textarea id="systemInstructions" placeholder="Enter system instructions for Korean correction..." rows="6"></textarea>
        </div>
        
        <div class="controls">
            <button id="micButton" class="mic-button" type="button">
                <span class="mic-icon">🎤</span>
                <span id="micButtonText">Start Recording</span>
            </button>
            <div id="volumeIndicator" class="volume-indicator">🔊</div>
        </div>
        
        <div class="controls" id="manualControls" style="display: none;">
            <button id="commitButton" class="audio-button" type="button">
                📤 Commit Audio
            </button>
            <button id="createResponseButton" class="audio-button" type="button">
                🗣️ Get Response
            </button>
            <label>
                <input type="checkbox" id="autoCommit"> Auto-commit on silence
            </label>
        </div>
        
        <div id="status" class="status disconnected">
            Disconnected - Click "Start Recording" to begin
        </div>
        
        <div id="error" class="error" style="display: none;"></div>
        
        <div id="conversation" class="conversation" style="display: none;">
            <div id="conversationContent"></div>
        </div>
        
        <!-- Debug Panel -->
        <div class="debug-panel">
            <div class="debug-header" onclick="toggleDebugPanel()">
                <span>🔧 Debug Panel</span>
                <span id="debugToggle">▼</span>
            </div>
            <div id="debugContent" class="debug-content">
                <!-- Connection Status -->
                <div class="connection-status">
                    <div id="connectionDot" class="connection-dot"></div>
                    <span id="connectionText">Disconnected</span>
                </div>
                
                <!-- Audio Visualizer -->
                <div class="audio-visualizer">
                    <div class="waveform-container">
                        <span style="color: #e2e8f0; font-size: 12px; min-width: 80px;">🎤 Audio Input:</span>
                        <div class="waveform-bars" id="waveformBars">
                            <!-- Waveform bars will be generated by JavaScript -->
                        </div>
                    </div>
                    <div class="audio-stats">
                        <div class="audio-stat">
                            <div class="audio-stat-label">Volume</div>
                            <div class="audio-stat-value" id="volumeLevel">0%</div>
                        </div>
                        <div class="audio-stat">
                            <div class="audio-stat-label">Sample Rate</div>
                            <div class="audio-stat-value" id="sampleRate">-</div>
                        </div>
                        <div class="audio-stat">
                            <div class="audio-stat-label">Channels</div>
                            <div class="audio-stat-value" id="channels">-</div>
                        </div>
                        <div class="audio-stat">
                            <div class="audio-stat-label">Latency</div>
                            <div class="audio-stat-value" id="latency">-</div>
                        </div>
                    </div>
                </div>
                
                <!-- API Communication Log -->
                <div>
                    <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 8px;">
                        <span style="font-weight: 600; color: #495057;">📡 API Communications</span>
                        <div class="debug-actions">
                            <button class="debug-btn" onclick="clearDebugLog()">Clear Log</button>
                            <button class="debug-btn" onclick="exportDebugLog()">Export Log</button>
                        </div>
                    </div>
                    <div id="debugLog" class="debug-log"></div>
                </div>
            </div>
        </div>
    </div>

    <script>
        class RealtimeKoreanCorrection {
            constructor() {
                this.pc = null;
                this.dc = null;
                this.audioContext = null;
                this.mediaStream = null;
                this.microphone = null;
                this.processor = null;
                this.isRecording = false;
                this.isConnected = false;
                
                // Manual turn detection properties
                this.isSpeaking = false;
                this.silenceStartTime = null;
                this.silenceThreshold = 500; // ms of silence before auto-commit
                this.volumeThreshold = 5; // Volume threshold for voice activity
                this.autoCommitEnabled = false;
                
                // Debug properties
                this.debugLog = [];
                this.waveformBars = [];
                this.audioStats = {
                    volume: 0,
                    sampleRate: 0,
                    channels: 0,
                    latency: 0
                };
                
                this.initElements();
                this.initDebugPanel();
                this.loadSettings();
                this.setupEventListeners();
            }
            
            initElements() {
                this.micButton = document.getElementById('micButton');
                this.micButtonText = document.getElementById('micButtonText');
                this.statusDiv = document.getElementById('status');
                this.errorDiv = document.getElementById('error');
                this.conversationDiv = document.getElementById('conversation');
                this.conversationContent = document.getElementById('conversationContent');
                this.apiKeyInput = document.getElementById('apiKey');
                this.systemInstructionsInput = document.getElementById('systemInstructions');
                this.volumeIndicator = document.getElementById('volumeIndicator');
                
                // Manual control elements
                this.manualControls = document.getElementById('manualControls');
                this.commitButton = document.getElementById('commitButton');
                this.createResponseButton = document.getElementById('createResponseButton');
                this.autoCommitCheckbox = document.getElementById('autoCommit');
                
                // Debug elements
                this.debugLogElement = document.getElementById('debugLog');
                this.waveformBarsElement = document.getElementById('waveformBars');
                this.connectionDot = document.getElementById('connectionDot');
                this.connectionText = document.getElementById('connectionText');
                this.volumeLevelElement = document.getElementById('volumeLevel');
                this.sampleRateElement = document.getElementById('sampleRate');
                this.channelsElement = document.getElementById('channels');
                this.latencyElement = document.getElementById('latency');
            }
            
            initDebugPanel() {
                // Create waveform bars
                for (let i = 0; i < 50; i++) {
                    const bar = document.createElement('div');
                    bar.className = 'waveform-bar';
                    bar.style.height = '4px';
                    this.waveformBarsElement.appendChild(bar);
                    this.waveformBars.push(bar);
                }
                
                this.logDebug('info', 'Debug panel initialized');
            }
            
            logDebug(type, message, data = null) {
                const timestamp = new Date().toISOString().split('T')[1].split('.')[0];
                const logEntry = {
                    timestamp,
                    type,
                    message,
                    data
                };
                
                this.debugLog.push(logEntry);
                
                // Format log entry for display
                let logText = `<span class="timestamp">[${timestamp}]</span> `;
                logText += `<span class="${type}">${type.toUpperCase()}</span>: ${message}`;
                
                if (data) {
                    logText += `\n${JSON.stringify(data, null, 2)}`;
                }
                
                // Add to debug log element
                const logDiv = document.createElement('div');
                logDiv.innerHTML = logText;
                this.debugLogElement.appendChild(logDiv);
                
                // Auto-scroll to bottom
                this.debugLogElement.scrollTop = this.debugLogElement.scrollHeight;
                
                // Keep only last 100 entries
                if (this.debugLog.length > 100) {
                    this.debugLog.shift();
                    this.debugLogElement.removeChild(this.debugLogElement.firstChild);
                }
            }
            
            updateConnectionStatus(status, text) {
                this.connectionDot.className = `connection-dot ${status}`;
                this.connectionText.textContent = text;
                this.logDebug('info', `Connection status: ${text}`);
            }
            
            loadSettings() {
                const savedApiKey = localStorage.getItem('openai_api_key');
                const savedSystemInstructions = localStorage.getItem('system_instructions');
                
                if (savedApiKey) {
                    this.apiKeyInput.value = savedApiKey;
                }
                
                if (savedSystemInstructions) {
                    this.systemInstructionsInput.value = savedSystemInstructions;
                } else {
                    // Default system instructions for Korean correction
                    this.systemInstructionsInput.value = `You are a Korean language correction assistant. When you receive Korean audio:

1. Provide real-time pronunciation feedback
2. Correct grammar and vocabulary mistakes
3. Suggest more natural expressions
4. Respond in both Korean and English
5. Be encouraging and helpful

Keep responses concise and focused on the most important corrections.`;
                }
            }
            
            setupEventListeners() {
                this.micButton.addEventListener('click', () => this.toggleRecording());
                
                this.apiKeyInput.addEventListener('input', (e) => {
                    localStorage.setItem('openai_api_key', e.target.value);
                });
                
                this.systemInstructionsInput.addEventListener('input', (e) => {
                    localStorage.setItem('system_instructions', e.target.value);
                });
                
                // Manual control event listeners
                this.commitButton.addEventListener('click', () => this.commitAudioBuffer());
                this.createResponseButton.addEventListener('click', () => this.createResponse());
                this.autoCommitCheckbox.addEventListener('change', (e) => {
                    this.autoCommitEnabled = e.target.checked;
                    this.logDebug('info', `Auto-commit ${this.autoCommitEnabled ? 'enabled' : 'disabled'}`);
                });
            }
            
            async toggleRecording() {
                if (!this.isRecording) {
                    await this.startRecording();
                } else {
                    await this.stopRecording();
                }
            }
            
            async startRecording() {
                const apiKey = this.apiKeyInput.value.trim();
                if (!apiKey) {
                    this.showError('Please enter your OpenAI API key');
                    return;
                }
                
                try {
                    this.updateStatus('connecting', 'Connecting to OpenAI...');
                    this.updateConnectionStatus('connecting', 'Connecting to OpenAI...');
                    this.micButton.disabled = true;
                    this.logDebug('info', 'Starting recording session');
                    
                    // Initialize audio
                    this.logDebug('info', 'Initializing audio...');
                    await this.initializeAudio();
                    
                    // Connect to OpenAI Realtime API
                    this.logDebug('info', 'Connecting to OpenAI Realtime API...');
                    await this.connectToOpenAI(apiKey);
                    
                    this.isRecording = true;
                    this.micButton.classList.add('recording');
                    this.micButtonText.textContent = 'Stop Recording';
                    this.micButton.disabled = false;
                    this.updateStatus('connected', 'Connected - Manual turn detection active');
                    this.updateConnectionStatus('connected', 'Connected - Manual turn detection active');
                    this.conversationDiv.style.display = 'block';
                    this.manualControls.style.display = 'flex';
                    this.logDebug('info', 'Recording session started successfully with manual turn detection');
                    
                } catch (error) {
                    this.logDebug('error', 'Error starting recording', { error: error.message });
                    this.showError('Error starting recording: ' + error.message);
                    this.micButton.disabled = false;
                    this.updateStatus('disconnected', 'Connection failed');
                    this.updateConnectionStatus('', 'Connection failed');
                }
            }
            
            async stopRecording() {
                this.logDebug('info', 'Stopping recording session');
                this.isRecording = false;
                this.micButton.classList.remove('recording');
                this.micButtonText.textContent = 'Start Recording';
                this.updateStatus('disconnected', 'Disconnected');
                this.updateConnectionStatus('', 'Disconnected');
                this.manualControls.style.display = 'none';
                
                // Close WebRTC connections
                if (this.pc) {
                    this.logDebug('info', 'Closing WebRTC peer connection');
                    this.pc.close();
                    this.pc = null;
                }
                
                if (this.dc) {
                    this.logDebug('info', 'Closing WebRTC data channel');
                    this.dc.close();
                    this.dc = null;
                }
                
                // Stop audio processing
                if (this.processor) {
                    this.logDebug('info', 'Stopping audio processing');
                    this.processor.disconnect();
                    this.microphone.disconnect();
                    this.processor = null;
                    this.microphone = null;
                }
                
                if (this.mediaStream) {
                    this.logDebug('info', 'Stopping media stream');
                    this.mediaStream.getTracks().forEach(track => track.stop());
                    this.mediaStream = null;
                }
                
                if (this.audioContext) {
                    this.logDebug('info', 'Closing audio context');
                    await this.audioContext.close();
                    this.audioContext = null;
                }
                
                this.isConnected = false;
                this.logDebug('info', 'Recording session stopped');
            }
            
            async connectToOpenAI(apiKey) {
                this.logDebug('info', 'Creating WebRTC peer connection');
                // Create WebRTC connection
                this.pc = new RTCPeerConnection();
                
                // Add audio track
                const audioTrack = this.mediaStream.getAudioTracks()[0];
                this.pc.addTrack(audioTrack, this.mediaStream);
                this.logDebug('info', 'Added audio track to peer connection');
                
                // Handle remote audio
                this.pc.ontrack = (event) => {
                    this.logDebug('info', 'Received remote audio track');
                    const audio = document.createElement('audio');
                    audio.srcObject = event.streams[0];
                    audio.autoplay = true;
                    audio.id = 'remoteAudio';
                    
                    // Remove existing audio element
                    const existing = document.getElementById('remoteAudio');
                    if (existing) existing.remove();
                    
                    document.body.appendChild(audio);
                };
                
                // Create data channel
                this.dc = this.pc.createDataChannel('oai-events');
                this.logDebug('info', 'Created data channel');
                
                this.dc.onopen = () => {
                    this.isConnected = true;
                    this.logDebug('info', 'Data channel opened');
                    
                    // Send session configuration
                    const instructions = this.systemInstructionsInput.value || 'You are a Korean language correction assistant. When you receive Korean audio: 1. Provide real-time pronunciation feedback 2. Correct grammar and vocabulary mistakes 3. Suggest more natural expressions 4. Respond in both Korean and English 5. Be encouraging and helpful Keep responses concise and focused on the most important corrections.';
                    
                    const sessionConfig = {
                        type: 'session.update',
                        session: {
                            modalities: ['text', 'audio'],
                            instructions: instructions,
                            voice: 'alloy',
                            input_audio_format: 'pcm16',
                            output_audio_format: 'pcm16',
                            input_audio_transcription: {
                                model: 'whisper-1'
                            },
                            turn_detection: {
                                type: 'none'
                            }
                        }
                    };
                    
                    this.logDebug('request', 'Sending session configuration', sessionConfig);
                    this.sendToOpenAI(sessionConfig);
                };
                
                this.dc.onmessage = (event) => {
                    const message = JSON.parse(event.data);
                    this.logDebug('response', 'Received message from OpenAI', message);
                    this.handleMessage(message);
                };
                
                this.dc.onclose = () => {
                    this.isConnected = false;
                    this.logDebug('info', 'Data channel closed');
                    if (this.isRecording) {
                        this.stopRecording();
                    }
                };
                
                // Create and send offer
                this.logDebug('info', 'Creating WebRTC offer');
                const offer = await this.pc.createOffer();
                await this.pc.setLocalDescription(offer);
                
                this.logDebug('request', 'Sending WebRTC offer to OpenAI', { sdp: offer.sdp.substring(0, 100) + '...' });
                const response = await fetch('https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${apiKey}`,
                        'Content-Type': 'application/sdp'
                    },
                    body: offer.sdp
                });
                
                if (!response.ok) {
                    const errorText = await response.text();
                    this.logDebug('error', 'OpenAI API request failed', { 
                        status: response.status, 
                        statusText: response.statusText,
                        error: errorText 
                    });
                    throw new Error(`Connection failed: ${response.statusText}`);
                }
                
                const answerSdp = await response.text();
                this.logDebug('response', 'Received WebRTC answer from OpenAI', { sdp: answerSdp.substring(0, 100) + '...' });
                await this.pc.setRemoteDescription({
                    type: 'answer',
                    sdp: answerSdp
                });
                
                // Wait for connection
                return new Promise((resolve, reject) => {
                    const timeout = setTimeout(() => {
                        this.logDebug('error', 'WebRTC connection timeout');
                        reject(new Error('Connection timeout'));
                    }, 10000);
                    
                    this.pc.addEventListener('connectionstatechange', () => {
                        this.logDebug('info', `WebRTC connection state: ${this.pc.connectionState}`);
                        if (this.pc.connectionState === 'connected') {
                            clearTimeout(timeout);
                            resolve();
                        } else if (this.pc.connectionState === 'failed') {
                            clearTimeout(timeout);
                            reject(new Error('Connection failed'));
                        }
                    });
                });
            }
            
            handleMessage(message) {
                switch (message.type) {
                    case 'session.created':
                        this.logDebug('info', 'OpenAI session created', message);
                        console.log('Session created:', message);
                        break;
                        
                    case 'conversation.item.input_audio_transcription.completed':
                        const userText = message.transcript;
                        this.logDebug('info', 'User speech transcribed', { transcript: userText });
                        this.addMessage('user', userText);
                        break;
                        
                    case 'response.audio.delta':
                        this.logDebug('info', 'Received audio delta from OpenAI');
                        // Audio is handled automatically by WebRTC
                        break;
                        
                    case 'response.text.delta':
                        // Handle text response chunks
                        if (message.delta) {
                            this.logDebug('info', 'Received text delta from OpenAI', { delta: message.delta });
                            this.appendToLastAssistantMessage(message.delta);
                        }
                        break;
                        
                    case 'response.done':
                        this.logDebug('info', 'OpenAI response completed');
                        console.log('Response completed');
                        break;
                        
                    case 'error':
                        this.logDebug('error', 'OpenAI API error', message.error);
                        this.showError('OpenAI Error: ' + message.error.message);
                        break;
                        
                    case 'session.updated':
                        this.logDebug('info', 'OpenAI session updated', message);
                        break;
                        
                    case 'input_audio_buffer.committed':
                        this.logDebug('info', 'Audio buffer committed to OpenAI');
                        break;
                        
                    case 'input_audio_buffer.speech_started':
                        this.logDebug('info', 'Speech detection started');
                        break;
                        
                    case 'input_audio_buffer.speech_stopped':
                        this.logDebug('info', 'Speech detection stopped');
                        break;
                        
                    case 'conversation.item.created':
                        this.logDebug('info', 'Conversation item created', message);
                        break;
                        
                    case 'response.created':
                        this.logDebug('info', 'Response created', message);
                        break;
                        
                    case 'response.output_item.added':
                        this.logDebug('info', 'Output item added', message);
                        break;
                        
                    case 'response.content_part.added':
                        this.logDebug('info', 'Content part added', message);
                        break;
                        
                    case 'response.audio_transcript.delta':
                        this.logDebug('info', 'Audio transcript delta', message);
                        break;
                        
                    case 'response.audio.done':
                        this.logDebug('info', 'Audio response completed');
                        break;
                        
                    case 'response.text.done':
                        this.logDebug('info', 'Text response completed');
                        break;
                        
                    default:
                        this.logDebug('info', `Unknown message type: ${message.type}`, message);
                        console.log('Received message:', message);
                }
            }
            
            async initializeAudio() {
                this.logDebug('info', 'Requesting microphone access');
                this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                this.mediaStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: { 
                        echoCancellation: true, 
                        noiseSuppression: true,
                        sampleRate: 24000,
                        channelCount: 1 
                    } 
                });
                
                // Update audio stats
                this.audioStats.sampleRate = this.audioContext.sampleRate;
                this.audioStats.channels = this.mediaStream.getAudioTracks()[0].getSettings().channelCount || 1;
                this.audioStats.latency = this.audioContext.baseLatency * 1000; // Convert to ms
                
                this.updateAudioStats();
                this.logDebug('info', 'Audio initialized', {
                    sampleRate: this.audioStats.sampleRate,
                    channels: this.audioStats.channels,
                    latency: this.audioStats.latency
                });
                
                this.microphone = this.audioContext.createMediaStreamSource(this.mediaStream);
                this.processor = this.audioContext.createScriptProcessor(4096, 1, 1);
                
                this.processor.onaudioprocess = (event) => {
                    const inputData = event.inputBuffer.getChannelData(0);
                    this.visualizeAudio(inputData);
                };
                
                this.microphone.connect(this.processor);
                this.processor.connect(this.audioContext.destination);
                
                this.logDebug('info', 'Audio processing pipeline established');
            }
            
            updateAudioStats() {
                this.sampleRateElement.textContent = `${this.audioStats.sampleRate} Hz`;
                this.channelsElement.textContent = this.audioStats.channels;
                this.latencyElement.textContent = `${this.audioStats.latency.toFixed(1)} ms`;
            }
            
            visualizeAudio(audioData) {
                // Calculate RMS volume
                let sum = 0;
                for (let i = 0; i < audioData.length; i++) {
                    sum += audioData[i] * audioData[i];
                }
                const rmsVolume = Math.sqrt(sum / audioData.length);
                const volume = Math.min(rmsVolume * 100, 100);
                
                // Update volume stats
                this.audioStats.volume = volume;
                this.volumeLevelElement.textContent = `${volume.toFixed(1)}%`;
                
                // Update volume indicator
                this.volumeIndicator.classList.toggle('active', volume > 10);
                
                // Voice Activity Detection for manual turn detection
                this.handleVoiceActivity(volume);
                
                // Create waveform visualization
                const segmentSize = Math.floor(audioData.length / this.waveformBars.length);
                for (let i = 0; i < this.waveformBars.length; i++) {
                    const start = i * segmentSize;
                    const end = start + segmentSize;
                    
                    // Calculate average amplitude for this segment
                    let segmentSum = 0;
                    for (let j = start; j < end && j < audioData.length; j++) {
                        segmentSum += Math.abs(audioData[j]);
                    }
                    const segmentAvg = segmentSum / segmentSize;
                    
                    // Convert to height (4px to 56px)
                    const height = Math.max(4, Math.min(56, segmentAvg * 200));
                    
                    this.waveformBars[i].style.height = `${height}px`;
                    this.waveformBars[i].classList.toggle('active', segmentAvg > 0.01);
                }
            }
            
            handleVoiceActivity(volume) {
                const currentTime = Date.now();
                const wasSpeaking = this.isSpeaking;
                this.isSpeaking = volume > this.volumeThreshold;
                
                if (this.isSpeaking && !wasSpeaking) {
                    // Started speaking
                    this.silenceStartTime = null;
                    this.logDebug('info', 'Voice activity detected - speech started');
                    this.updateStatus('connected', 'Connected - Speaking detected');
                } else if (!this.isSpeaking && wasSpeaking) {
                    // Stopped speaking
                    this.silenceStartTime = currentTime;
                    this.logDebug('info', 'Voice activity stopped - silence detected');
                    this.updateStatus('connected', 'Connected - Silence detected');
                } else if (!this.isSpeaking && this.silenceStartTime) {
                    // Check if we've been silent long enough for auto-commit
                    const silenceDuration = currentTime - this.silenceStartTime;
                    if (this.autoCommitEnabled && silenceDuration >= this.silenceThreshold) {
                        this.logDebug('info', `Auto-committing after ${silenceDuration}ms of silence`);
                        this.commitAudioBuffer();
                        this.silenceStartTime = null;
                    }
                }
            }
            
            commitAudioBuffer() {
                if (!this.isConnected) {
                    this.logDebug('error', 'Cannot commit audio - not connected');
                    return;
                }
                
                const commitMessage = {
                    type: 'input_audio_buffer.commit'
                };
                
                this.logDebug('info', 'Committing audio buffer');
                this.sendToOpenAI(commitMessage);
                this.updateStatus('connected', 'Connected - Audio committed');
            }
            
            createResponse() {
                if (!this.isConnected) {
                    this.logDebug('error', 'Cannot create response - not connected');
                    return;
                }
                
                const responseMessage = {
                    type: 'response.create',
                    response: {
                        modalities: ['text', 'audio'],
                        instructions: 'Please provide Korean language correction feedback based on the audio input.'
                    }
                };
                
                this.logDebug('info', 'Creating response');
                this.sendToOpenAI(responseMessage);
                this.updateStatus('connected', 'Connected - Generating response...');
            }
            
            sendToOpenAI(message) {
                if (this.dc && this.dc.readyState === 'open') {
                    this.logDebug('request', 'Sending message to OpenAI', message);
                    this.dc.send(JSON.stringify(message));
                } else {
                    this.logDebug('error', 'Cannot send message - data channel not open', { readyState: this.dc?.readyState });
                }
            }
            
            addMessage(type, content) {
                const messageDiv = document.createElement('div');
                messageDiv.className = `message ${type}`;
                
                const labelDiv = document.createElement('div');
                labelDiv.className = 'message-label';
                labelDiv.textContent = type === 'user' ? 'You' : 'Assistant';
                
                const contentDiv = document.createElement('div');
                contentDiv.textContent = content;
                
                messageDiv.appendChild(labelDiv);
                messageDiv.appendChild(contentDiv);
                
                this.conversationContent.appendChild(messageDiv);
                this.conversationDiv.scrollTop = this.conversationDiv.scrollHeight;
            }
            
            appendToLastAssistantMessage(text) {
                const messages = this.conversationContent.querySelectorAll('.message.assistant');
                let lastMessage = messages[messages.length - 1];
                
                if (!lastMessage) {
                    this.addMessage('assistant', text);
                    return;
                }
                
                const contentDiv = lastMessage.querySelector('div:last-child');
                contentDiv.textContent += text;
                this.conversationDiv.scrollTop = this.conversationDiv.scrollHeight;
            }
            
            updateStatus(type, message) {
                this.statusDiv.className = `status ${type}`;
                this.statusDiv.textContent = message;
            }
            
            showError(message) {
                this.errorDiv.textContent = message;
                this.errorDiv.style.display = 'block';
                setTimeout(() => {
                    this.errorDiv.style.display = 'none';
                }, 5000);
            }
        }
        
        // Global instance for debug panel functions
        let appInstance = null;
        
        // Global functions for debug panel
        function toggleDebugPanel() {
            const content = document.getElementById('debugContent');
            const toggle = document.getElementById('debugToggle');
            
            if (content.classList.contains('collapsed')) {
                content.classList.remove('collapsed');
                toggle.textContent = '▼';
            } else {
                content.classList.add('collapsed');
                toggle.textContent = '▶';
            }
        }
        
        function clearDebugLog() {
            if (appInstance) {
                appInstance.debugLog = [];
                appInstance.debugLogElement.innerHTML = '';
                appInstance.logDebug('info', 'Debug log cleared');
            }
        }
        
        function exportDebugLog() {
            if (appInstance && appInstance.debugLog.length > 0) {
                const logData = JSON.stringify(appInstance.debugLog, null, 2);
                const blob = new Blob([logData], { type: 'application/json' });
                const url = URL.createObjectURL(blob);
                
                const a = document.createElement('a');
                a.href = url;
                a.download = `debug-log-${new Date().toISOString().split('T')[0]}.json`;
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
                
                appInstance.logDebug('info', 'Debug log exported');
            }
        }
        
        // Initialize the app when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            appInstance = new RealtimeKoreanCorrection();
        });
    </script>
</body>
</html>
